{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "Imersão Dev Agentes de IA - Alura e Google Gemini\n",
        "---\n",
        "\n",
        "Aula 01 - Classificação de intenções com IA\n",
        "---\n",
        "\n"
      ],
      "metadata": {
        "id": "cudhEjWchrc7"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 36,
      "metadata": {
        "id": "EyswbL-Fkszh"
      },
      "outputs": [],
      "source": [
        "!pip install -q --upgrade langchain langchain-google-genai google-generativeai"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import userdata\n",
        "from langchain_google_genai import ChatGoogleGenerativeAI\n",
        "\n",
        "\n",
        "GOOGLE_API_KEY = userdata.get('GEMINI_API_KEY')"
      ],
      "metadata": {
        "id": "wT7G_MZDdY-u"
      },
      "execution_count": 37,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "cQjzxpFmvEXS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# temperatura entre 0 e 1, 1 sendo criativo"
      ],
      "metadata": {
        "id": "EYRZePuljqHP"
      },
      "execution_count": 38,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "-rzEdAwDoCF4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "llm = ChatGoogleGenerativeAI(\n",
        "    model=\"gemini-2.5-flash\",\n",
        "    temperatura=0.8,\n",
        "    api_key=GOOGLE_API_KEY\n",
        ")"
      ],
      "metadata": {
        "id": "yEm0pIm0fzBj"
      },
      "execution_count": 39,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "resp_test = llm.invoke(\"Quem é você?\")\n",
        "print(resp_test.content)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "l9yPh5wxi4-w",
        "outputId": "3e9a2c8f-2648-4ccc-83d8-a69337c05361"
      },
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Eu sou um modelo de linguagem grande, treinado pelo Google.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Qual o objetivo do Agente?"
      ],
      "metadata": {
        "id": "dCczMIOskByc"
      },
      "execution_count": 41,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "TRIAGEM_PROMPT = (\n",
        "    \"Você é um gerador de README para perfil do GitHub. \"\n",
        "    \"Dada a mensagem do usuário, retorne SOMENTE um JSON com:\\n\"\n",
        "    \"{\\n\"\n",
        "    '  \"decisao\": \"AUTO_COMPLETAR\" | \"PEDIR_INFO\" | \"GERAR_BIO\",\\n'\n",
        "    '  \"carreira_academica\": \"ESTUDANTE\" | \"FORMADO/A\" | \"PÓS-GRADUADO/A\",\\n'\n",
        "    '  \"experiencia_profissional\": \"ESTAGIÁRIO/A\" | \"JÚNIOR\" | \"PLENO\" | \"SÊNIOR | \"ESPECIALISTA\",\\n'\n",
        "    '  \"campos_faltantes: [\"...\"]\\n'\n",
        "    \"}\\n\"\n",
        "    \"Regras:\\n\"\n",
        "    '- **AUTO_COMPLETAR**: Perfil completo da pessoa, contendo nome, função, senioridade, hard skills e soft skills (Ex: \"Meu nome é Maria, sou Especialista em TI Sênior, programadora javascript e autodidata\", \"Meu nome é José, sou estudante buscando estágio em TI, sei HMTL, CSS e JS\").\\n'\n",
        "    '- **PEDIR_INFO**: Mensagem de apresentação vaga ou que faltam informações para identificar o perfil (Ex: \"Sou estudante\", \"Trabalho com TI\").\\n'\n",
        "    '- **GERAR_BIO**: Solicitação para criar Bio ou Perfil do GitHub com as informações da mensagem de forma completa e precisa.\"'\n",
        ")"
      ],
      "metadata": {
        "id": "HgFrsYttlwQT"
      },
      "execution_count": 42,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from pydantic import BaseModel, Field\n",
        "from typing import Literal, List, Dict\n",
        "\n",
        "class TriagemOut(BaseModel):\n",
        "    decisao: Literal[\"AUTO_COMPLETAR\", \"PEDIR_INFO\", \"GERAR_BIO\"]\n",
        "    carreira_academica: Literal[\"ESTUDANTE\", \"FORMADO/A\", \"PÓS-GRADUADO/A\"]\n",
        "    experiencia_profissional: Literal[\"ESTAGIÁRIO/A\", \"JÚNIOR\", \"PLENO\", \"SÊNIOR\", \"ESPECIALISTA\"]\n",
        "    campos_faltantes: List[str] = Field(default_factory=list)"
      ],
      "metadata": {
        "id": "CrddVUPun4nx"
      },
      "execution_count": 43,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "llm_triagem = ChatGoogleGenerativeAI(\n",
        "    model=\"gemini-2.5-flash\",\n",
        "    temperature=0.0,\n",
        "    api_key=GOOGLE_API_KEY\n",
        ")"
      ],
      "metadata": {
        "id": "QG-Jh7gLoS1C"
      },
      "execution_count": 44,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain_core.messages import SystemMessage, HumanMessage\n",
        "\n",
        "triagem_chain = llm_triagem.with_structured_output(TriagemOut)\n",
        "\n",
        "def triagem(mensagem: str) -> Dict:\n",
        "    saida: TriagemOut = triagem_chain.invoke([\n",
        "        SystemMessage(content=TRIAGEM_PROMPT),\n",
        "        HumanMessage(content=mensagem)\n",
        "    ])\n",
        "\n",
        "    return saida.model_dump()"
      ],
      "metadata": {
        "id": "5ctVeazKohil"
      },
      "execution_count": 45,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "testes = [\"Meu nome é Ana Maria sou Especialista de TI, Formada e conclui a Pós, sou Analista nível Pleno\", \"Meu Nome é Maria, sou estudante e estagiária\"]"
      ],
      "metadata": {
        "id": "W98N-7G8q2GV"
      },
      "execution_count": 46,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for msg_teste in testes:\n",
        "    print(f\"Pergunta: {msg_teste}\\n -> Resposta: {triagem(msg_teste)}\\n\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "e5WstcNKrTaH",
        "outputId": "14fe194c-98ef-417b-c41d-35b316b8a94f"
      },
      "execution_count": 48,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Pergunta: Meu nome é Ana Maria sou Especialista de TI, Formada e conclui a Pós, sou Analista nível Pleno\n",
            " -> Resposta: {'decisao': 'AUTO_COMPLETAR', 'carreira_academica': 'PÓS-GRADUADO/A', 'experiencia_profissional': 'PLENO', 'campos_faltantes': []}\n",
            "\n",
            "Pergunta: Meu Nome é Maria, sou estudante e estagiária\n",
            " -> Resposta: {'decisao': 'AUTO_COMPLETAR', 'carreira_academica': 'ESTUDANTE', 'experiencia_profissional': 'ESTAGIÁRIO/A', 'campos_faltantes': []}\n",
            "\n"
          ]
        }
      ]
    }
  ]
}